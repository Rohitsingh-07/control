# Why do we do Feature Engineering in ML or Deep Learning Models

**Feature Engineering** is one of the most important steps in building effective **Machine Learning (ML) or Deep Learning (DL) models**. Itâ€™s the process of transforming raw data into meaningful features that make models learn better.  

---

## ðŸ”‘ 1. Improve Model Performance
- Raw data is often noisy, incomplete, or unstructured.  
- By creating better features (e.g., ratios, interaction terms, log transformations), models can capture important patterns and relationships.  
- **Example:** Instead of just using *height* and *weight*, creating a *BMI feature* can improve prediction accuracy in health models.  

---

## ðŸ”‘ 2. Reduce Complexity & Noise
- Raw features may have irrelevant or redundant information.  
- Engineering helps filter out noise, smooth data, and highlight what truly matters.  
- **Example:** Converting *date-time* into *day-of-week* or *hour-of-day* reduces complexity and improves interpretability.  

---

## ðŸ”‘ 3. Make Data Suitable for Algorithms
- Many ML/DL algorithms expect numeric, scaled, or encoded features.  
- Feature engineering ensures compatibility.  
- **Examples:**  
  - Categorical variables â†’ One-hot encoding / label encoding  
  - Text â†’ TF-IDF, embeddings  
  - Images â†’ Edge detection, pixel normalization  

---

## ðŸ”‘ 4. Enable Generalization
- Good features help models learn underlying trends rather than memorizing training data.  
- This reduces **overfitting** and improves performance on unseen data.  

---

## ðŸ”‘ 5. Domain Knowledge Incorporation
- Feature engineering lets us inject **human/domain knowledge** into models.  
- **Example:** In fraud detection, instead of just using transaction amounts, we can create features like *average transaction per day* or *time since last transaction.*  

---

## ðŸ”‘ 6. Improve Training Efficiency
- Well-designed features reduce the amount of data and computation needed.  
- This is especially useful in deep learning when raw data is huge and models are expensive to train.  

---

## âœ… In Short
Feature Engineering is done to **improve accuracy, efficiency, and generalization** of ML/DL models by making raw data more meaningful and suitable for learning.  

---
---
---

# What is WordNet?

**WordNet** is a large **lexical database of the English language**, developed at **Princeton University**. Itâ€™s widely used in **Natural Language Processing (NLP)** and **computational linguistics**.  

---

## ðŸ”‘ Key Points about WordNet

1. **Synsets (Synonym Sets)**  
   - Words that share the same meaning are grouped into sets called *synsets*.  
   - **Example:** *car, auto, automobile* â†’ one synset.  

2. **Semantic Relationships**  
   - Synsets are linked by relationships such as:  
     - **Hypernyms** (general terms) â†’ e.g., *vehicle* is a hypernym of *car*.  
     - **Hyponyms** (specific terms) â†’ e.g., *sedan* is a hyponym of *car*.  
     - **Meronyms** (part-of) â†’ e.g., *wheel* is a meronym of *car*.  
     - **Antonyms** (opposites) â†’ e.g., *hot* vs *cold*.  

3. **Hierarchical Structure**  
   - WordNet organizes concepts like a **semantic network/tree**, making it useful for understanding meanings, context, and relationships.  

4. **Applications**  
   - Word sense disambiguation (choosing the right meaning of a word in context).  
   - Semantic similarity (measuring closeness of word meanings).  
   - Information retrieval, chatbots, translation, sentiment analysis, etc.  

---

## ðŸ”¹ Example from WordNet
- *Car (noun)* â†’ "a motor vehicle with four wheels; usually propelled by an internal combustion engine."  
  - **Hypernym:** Vehicle  
  - **Hyponyms:** Sedan, SUV, Taxi  
  - **Meronyms:** Engine, Wheel, Door  

---

## âœ… In Short
**WordNet is like a dictionary + thesaurus + semantic network combined**, designed for both humans and machines to understand word meanings and relationships.  

