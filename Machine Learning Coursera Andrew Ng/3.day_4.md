# Linear Regression Model Part 2
---
- Recall that a training set in supervised learning includes both the input features, such as the size of the house and also the output targets, such as the price of the house.
- The output targets are the right answers to the model we'll learn from. To train the model, you feed the training set, both the input features and the output targets to your learning algorithm.
- Then the supervised learning algorithm produces some function which can be denoted as "f". Initially, this function used to be called as hypothesis, but we are going to denote it with "f".
- The function f takes a new input x and output and estimate or predicts, which is called as y-hat. In machine learning, the convention is that y-hat is the estimate or the prediction of y.
- The function f is called the model. X is called the input or the input feature, and the output of the model is the prediction, y-hat. The model's prediction is the estimated value of y.
- When the symbol is just the letter y, then that refers to the target, which is the actual true value in the training set. In contrast, y-hat is an estimate. y-hat may or may not be the actual true value.
- When we design a learning algorithm, an important question is how are we going to represent the function f, or in other words, what is the math formula we're going to use to compute f.
- For now, let's stick with f being a straight line. the function can be written as f_w,b of x equals w times x plus b. I'll define w and b soon.
- But for now, just know that w and b are numbers, and the values chosen for w and b will determine the prediction y-hat based on the input feature x

- This f_w b of x means f is a function that takes x as input, and depending on the values of w and b, f will output some value of a prediction y-hat. As an alternative to writing this, f_w, b of x, I'll sometimes just write f of x without explicitly including w and b into subscript

![image](https://github.com/user-attachments/assets/3f6943c0-85b6-467b-8c04-7cbe0e2e67aa)

- The diagram above shows all the plots and the representation of the equation.
- In the diagram above, the input feature x is on the horizontal axis and the output target y is on the vertical axis. The algorithm learns from this data and generates the best-fit line.
- This straight line as shown in the figure is the linear function. Here it's making predictions for the value of y using a streamline function of x.
- A question may arise that why are we using a linear function where linear function is just a fancy term for a straight line instead of some non linear function like a curve or a parabola.
- A linear function is relatively simple and easy to work with and it can be used as a foundation that will eventually help us to get to more complex models that are non-linear.
- This particular model has a name, it's called linear regression. More specifically, this is linear regression with one input variable. Another name for a linear model with one variable is univariate linear regression.
---

# Optional Lab
---
File Loc: D:\ML Andrew Ng\Linear Regression Lab.ipynb

- The first line in the lab imports numpy and matplotlib

```
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('./deeplearning.mplstyle')
```

- Here the line ```plt.style.use('./deeplearning.mplstyle')``` refers to
-  Sets a custom style for plots using Matplotlib's style.use() function.

./deeplearning.mplstyle refers to a local file (in the same directory as your script) that contains styling configurations.

.mplstyle files can define things like:

- Font sizes
- Background and grid color
- Line widths and colors
- Figure sizes
- And other visual preferences

Use this prompt in Chatgpt to get a clear idea

```
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('./deeplearning.mplstyle')

Explain what is hapenning here
```

2. The next step is we create two arrays of the given training data which contains input features of training data x_train and target y_train. Python f string is used for better code understanding

```
# x_train is the input variable (size in 1000 square feet)
# y_train is the target (price in 1000s of dollars)
x_train = np.array([1.0, 2.0])
y_train = np.array([300.0, 500.0])
print(f"x_train = {x_train}")
print(f"y_train = {y_train}")

Output-

x_train = [1. 2.]
y_train = [300. 500.]
```

##### Number of training examples m¬∂
- You will use m to denote the number of training examples. Numpy arrays have a .shape parameter. x_train.shape returns a python tuple with an entry for each dimension. x_train.shape[0] is the length of the array and number of examples as shown below.

```
# m is the number of training examples
print(f"x_train.shape: {x_train.shape}")
m = x_train.shape[0]
print(f"Number of training examples is: {m}")

Output -
x_train.shape: (2,)
Number of training examples is: 2
```

- We can also use the Python len() function as shown below

```
# m is the number of training examples
m = len(x_train)
print(f"Number of training examples is: {m}")
```

- Training example x_i, y_i
You will use (x (ùëñ), y (ùëñ)) to denote the  iùë°‚Ñé training example. Since Python is zero indexed, (x (0), y (0)) is (1.0, 300.0) and (x (1), y (1)) is (2.0, 500.0).

- To access a value in a Numpy array, one indexes the array with the desired offset. For example the syntax to access location zero of x_train is x_train[0]. Run the next code block below to get the  iùë°‚Ñé training example.

```
i = 0 # Change this to 1 to see (x^1, y^1)

x_i = x_train[i]
y_i = y_train[i]
print(f"(x^({i}), y^({i})) = ({x_i}, {y_i})")

(x^(0), y^(0)) = (1.0, 300.0)
```

