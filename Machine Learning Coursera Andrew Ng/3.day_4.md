# Linear Regression Model Part 2
---
- Recall that a training set in supervised learning includes both the input features, such as the size of the house and also the output targets, such as the price of the house.
- The output targets are the right answers to the model we'll learn from. To train the model, you feed the training set, both the input features and the output targets to your learning algorithm.
- Then the supervised learning algorithm produces some function which can be denoted as "f". Initially, this function used to be called as hypothesis, but we are going to denote it with "f".
- The function f takes a new input x and output and estimate or predicts, which is called as y-hat. In machine learning, the convention is that y-hat is the estimate or the prediction of y.
- The function f is called the model. X is called the input or the input feature, and the output of the model is the prediction, y-hat. The model's prediction is the estimated value of y.
- When the symbol is just the letter y, then that refers to the target, which is the actual true value in the training set. In contrast, y-hat is an estimate. y-hat may or may not be the actual true value.
- When we design a learning algorithm, an important question is how are we going to represent the function f, or in other words, what is the math formula we're going to use to compute f.
- For now, let's stick with f being a straight line. the function can be written as f_w,b of x equals w times x plus b. I'll define w and b soon.
- But for now, just know that w and b are numbers, and the values chosen for w and b will determine the prediction y-hat based on the input feature x

- This f_w b of x means f is a function that takes x as input, and depending on the values of w and b, f will output some value of a prediction y-hat. As an alternative to writing this, f_w, b of x, I'll sometimes just write f of x without explicitly including w and b into subscript

![image](https://github.com/user-attachments/assets/3f6943c0-85b6-467b-8c04-7cbe0e2e67aa)

- The diagram above shows all the plots and the representation of the equation.
- In the diagram above, the input feature x is on the horizontal axis and the output target y is on the vertical axis. The algorithm learns from this data and generates the best-fit line.
- This straight line as shown in the figure is the linear function. Here it's making predictions for the value of y using a streamline function of x.
- A question may arise that why are we using a linear function where linear function is just a fancy term for a straight line instead of some non linear function like a curve or a parabola.
- A linear function is relatively simple and easy to work with and it can be used as a foundation that will eventually help us to get to more complex models that are non-linear.
- This particular model has a name, it's called linear regression. More specifically, this is linear regression with one input variable. Another name for a linear model with one variable is univariate linear regression.
