## Feature Scaling Part 1

- Feature Scaling is a technique which will enable gradient descent to run much faster

![image](https://github.com/user-attachments/assets/a3a885c6-461c-4945-a969-c75fae6b6c23)

- The whole point of this slide was that if the values of feature is large, a good model will learn to choose a relatively small parameter (weight). Likewise, when the possible value of the feature are small, the reasonable value for its parameter will be relatively large

![image](https://github.com/user-attachments/assets/6727a8df-acb1-4640-8aa6-afa0c469c513)

- If we take a look at the scatter plot of the features where the size sqaure feet is the horizontal axis x1 and the number of bedrooms exudes is on the vertical axis.
- Here, we can see that the horizontal axis is on a much larger scale or much larger range of values compared to the vertical axis
- If we look at the contour plot, it has a much norrower range between zero and one whereas the vertical axis takes on much larger values. This is because a very small change on to w1 can have a very large impact on the estimated price and that's a very large impact on the cost J. In contrast, it takes a much large change in w2 in order to change the predictions much. And thus small changes to w2, don't change the cost function nearly as much

--- 
- If we were to use out training data as is, because the contours are so tall and skinny gradient descent may end up bouncing back and forth for a long time before it can finally find its way to the global minimum
![image](https://github.com/user-attachments/assets/24860c7f-2a97-4a16-97e0-a8afddef2844)

- In situations like this, a useful thing to do is scale the features. This means performing some transformations for your training data so that x1 say might range from 0 to 1 and x2 might also range from 0 to 1.
- The key point is that the re scale x1 and x2 are both now taking comparable ranges of values to each other. And if you run gradient descent on a cost function to find on this, re scaled x1 and x2 using this transformed data, then the contours will look more like circles and less tall and skinny. And gradient descent can find a much more direct path to the global minimum

![image](https://github.com/user-attachments/assets/faecb269-9d60-441d-aa66-98a5ea566a1f)

- Here is the representation of the graphs and the changes that we would see in them post feature scaling technique
---

## Feature Scaling Part 2

- We will look at how we can implement feature scaling, to take features that take on very different ranges of values and skill them to have comparable ranges of values to each other.
- There are multiple methods of feature scaling:
  1. For each example let's say x1, we can take the value of x1 and divide it from the maximum of the range of its value of the feature
![image](https://github.com/user-attachments/assets/e013c272-b995-4a38-8339-9be26b18d94f)

  2. We can also do Mean Normalization. In mean normalization, we can get the data between a scale that ranges between negative integers and positive integers. In mean normalization, we calculate the mean of the given training examples of a given feature. Then we subtract the mean from the training example let's say x1 and divide it by the difference Maximum and minimu value of the given range. (x1 - Mean)/ (Max Value - Min Value
![image](https://github.com/user-attachments/assets/666990ca-b53a-47d3-9722-f28746530732)

  3. There's one last common re-scaling method called Z-score Normalization. To implement Z score normalization, calculate Mean and Standard Deviation. Subtract the mean from the training example x1 and then divide by the standard deviation
![image](https://github.com/user-attachments/assets/5c4d2283-0516-4f7a-8ab3-632af11a054c)

- As a rule of thumb, when performing feature scaling, we might want to aim for getting the features to range from maybe anywhere around negative 1 to somewhere around plus one for each feature X.

![image](https://github.com/user-attachments/assets/60afc84e-91fe-414e-821a-eecade585bea)

- With feature scaling, we often get gradient descent to run much faster.

---

## Checking Gradient Descent for Convergence

- When running gradient descent, how can you tell if it is converging? That is, whether it's helping you to find parameters close to the global minimum of the cost function.
- The job of gradient descent is to find parameters w and b that hopefully minimize the cost function J. Let's plot the cost function J, which is calculated on the training set. Here, the horizontal axis is the number of iterations of gradient descent that we've run so far. We get the following curve

![image](https://github.com/user-attachments/assets/6f89088e-0fcd-42d4-b8cb-f3c9f51bc486)
- This curve is called the learning curve
- The curve of the cost should decrease after every iteration only then our model is working properly. If the cost increases by even 1 iteration then the alpha is chose too poorly and in such case, it means the alpha is too large
- After certain number of iterations, the cost level J does not drop gradually and starts to flatten. This is a good sign that the model is performing well and the gradient descent is converging
- Every application takes its own number of iterations for the gradient descent to get converged and hence it is difficult to say at what number of iteration the gradient descent would converge
- Another model to decide when your model is done training is with an automatic convergence test
- The greek alphabet epsilon. Let's let epsilon be a variable representing a small number, such as 0.001 or 10^-3. If the cost J decreases by less than this number epsilon on one iteration, then you're likely on this flattened part of the curve that you see on the left and you can declare convergence.
- Remember, convergence, hopefully in the case that you found parameters w and b that are close to the minimum possible value of J
- It is much better to look at the curve rather than the epsilon and is suggested much more

![image](https://github.com/user-attachments/assets/dd2abcf6-1e70-4e32-b868-9a53f3f75f0f)
