## Inference in Code

- Tensorflow is one of the leading frameworks to implementing deep learning algorithms. The other popular tool is Pytorch. One of the remarkable things about neural networks is the same algorithm can be applied to so many different applications
- We are going to take the coffee beans roasting algorithm. Can the learning algorithm help optimize the quality of the beans we get from a roasting process like this.
- While Roasting coffee beans, we can control two parameters. Temperature at which we'are heating as well as the duration
- In the diagram below, we see that the coffee we roasted is good or not. Cross here, the positive cross y equals 1 corresponds to good-tasting coffee, and all the circles correspond to bad coffee
- This shows that if the coffee is undercooked, overcooked or all the possibilities where the coffee could be bad tasting.

<img width="1870" height="908" alt="image" src="https://github.com/user-attachments/assets/26546c34-6b0c-49fe-97b2-2f2830884eaa" />

- There have actually been serious projects using Machine Learning to optimize the coffee roasting. The task is given a feature vector x with both temperature and duration, say 200 degrees Celsius for 17 minutes, how can we do inference in a neural network to get it to tell us whether or not this temperature and duration will result in a good coffee

---
- We are going to set x to be an aeeay of two numbers. The input fetures 200 degrees celsius and 17 minutes.
- Then we create Layer 1 as this first hidden layer, the neural network, as dense with units 3, which means three units or three hidden units in this layer using as the activation function, the sigmoid function.
- Next, we compute a1 by taking layer 1, which is exactly a function, and applying this function Layer 1 to the values of x. That's how we get a1, which is a goint to be a list of three numbers because Layer 1 had three units. So a1 here may be, 0.2, 0.7, 0.3.
- Next, for the 2nd hidden layer, Layer 2, would be dense. Now this time, it has one unit and again to sigmoid activation function, and you can then compute a2 by applying this Layer 2 function to the activation values from Layer 1 to a1.
- This will give the value of a2. If we wish to threshold it at 0.5, then we can just test if a2 is greater and equal to 0.5 and y-hat equals to one or zero positive or negative cross accordingly.
- That is how Inference is done in the neural network using Tensorflow.
- These are the key steps for forward propagation in how we compute a1 and a2 and optionally threshold a2.

<img width="1721" height="890" alt="image" src="https://github.com/user-attachments/assets/18e24a09-9b06-4a8e-9a98-c820c8d1a8a9" />

---

- We look at the example where we go back to handwritten digit classification problem. In this example, x is a list of pixel intensity values. So x is equal to a numpy array of this list of pixel intensity values. Then to initialize and carry out one step of forward propagation, Layer 1 is a dense layer with 25 units and the sigmoid activation function. We then compute a1 equals the layer 1 function applied to x.
- To build and carry out inference through the second layer, similarly, we set up Layer 2 as follows, and compute a2 as layer 2 applied to a1. Then finally, Layer 3 is the third and final dense layer.
- Then finally, you can optionally threshold a3 to come up with a binary prediction for y-hat. That's the syntax for carrying out inference in Tensorflow.

<img width="1857" height="925" alt="image" src="https://github.com/user-attachments/assets/ecdc6bef-e4ab-4aff-8ef9-f509a773735a" />
----

